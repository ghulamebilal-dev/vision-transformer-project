# Vision Transformer Image Classification Project

A complete implementation of Vision Transformer (ViT) for image classification with explainable AI, web dashboard, and hybrid models.

## ğŸš€ Features

- **Custom Vision Transformer** from scratch in PyTorch
- **Hybrid CNN + Transformer** architecture
- **Explainable AI** with attention visualization
- **Streamlit Dashboard** for interactive exploration
- **Pretrained ViT** comparison using timm
- **Training metrics** and model comparison

## ğŸ§© Project Structure

```bash
vision-transformer-project/
â”œâ”€â”€ app.py                         # Streamlit dashboard entrypoint
â”œâ”€â”€ compare_models.py               # Model comparison and evaluation
â”œâ”€â”€ explain_vit.py                  # ViT layer/attention explanation
â”œâ”€â”€ hybrid_model.py                 # Hybrid CNN + Transformer architecture
â”œâ”€â”€ vit_model.py                    # Custom Vision Transformer (from scratch)
â”œâ”€â”€ train.py                        # Training script for custom/hybrid models
â”œâ”€â”€ train_pretrained_vit.py         # Fine-tuning script for pretrained ViT
â”œâ”€â”€ utils.py                        # Data preprocessing & visualization utils
â”‚
â”œâ”€â”€ vit_model.pth                   # Custom ViT model weights (Git LFS)
â”œâ”€â”€ hybrid_model.pth                # Hybrid model weights (Git LFS)
â”œâ”€â”€ pretrained_vit_model.pth        # Fine-tuned Pretrained ViT weights (Git LFS)
â”‚
â”œâ”€â”€ vit_class_info.json             # Class labels for custom ViT
â”œâ”€â”€ hybrid_class_info.json          # Class labels for hybrid model
â”œâ”€â”€ pretrained_vit_class_info.json  # Class labels for fine-tuned ViT
â”‚
â”œâ”€â”€ results_comparison.csv          # Model performance summary
â”œâ”€â”€ detailed_results_comparison.csv # Detailed per-class evaluation results
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ packages.txt                    # System dependencies (git-lfs, libgl)
â”œâ”€â”€ README.md                       # Project documentation
â”‚
â””â”€â”€ data/                           # Dataset folder


---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/vision-transformer-project.git
cd vision-transformer-project

2ï¸âƒ£ Install dependencies

Python libraries:
pip install -r requirements.txt

Run the Streamlit App
streamlit run app.py


Youâ€™ll see the Vision Transformer Explorer interface, where you can:

Upload an image

Select a model (Custom ViT, Hybrid CNN+Transformer, or Pretrained ViT)

View predictions and attention heatmaps

ğŸ§  Model Evaluation Results

The models were evaluated on 300 validation samples (10 classes) using CUDA acceleration.
Using device: cuda
============================================================

ğŸ” Evaluating: Custom Vision Transformer
   Description: ViT implemented from scratch
   âœ… Accuracy: 0.810
   ğŸ“Š Parameters: 85,806,346 total
   âš ï¸  Challenging classes: electronics(0.63), flowers(0.63), animals(0.77)

ğŸ” Evaluating: Hybrid CNN+Transformer
   Description: ResNet18 features + Transformer encoder
   âœ… Accuracy: 1.000
   ğŸ“Š Parameters: 30,461,002 total
   âš ï¸  Challenging classes: animals(1.00), birds(1.00), cars(1.00)

ğŸ” Evaluating: Pretrained ViT (Fine-tuned)
   Description: ViT-Base from timm, fine-tuned
   âœ… Accuracy: 1.000
   ğŸ“Š Parameters: 85,806,346 total
   âš ï¸  Challenging classes: animals(1.00), birds(1.00), cars(1.00)
ğŸ“Š Model Comparison Summary

| Model                       |  Accuracy | Total Params | Trainable Params | Type             |
| :-------------------------- | --------: | -----------: | ---------------: | :--------------- |
| Custom Vision Transformer   | **0.810** |   85,806,346 |       85,806,346 | `vit`            |
| Hybrid CNN+Transformer      | **1.000** |   30,461,002 |       30,461,002 | `hybrid`         |
| Pretrained ViT (Fine-tuned) | **1.000** |   85,806,346 |       85,806,346 | `pretrained_vit` |

ğŸ† Best Model: Hybrid CNN+Transformer

Accuracy: 1.000

Parameters: 30,461,002

ğŸ“ˆ Summary:

Total models evaluated: 3

Best accuracy: 1.000

Average accuracy: 0.937




